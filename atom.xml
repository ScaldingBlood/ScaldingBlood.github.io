<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Rock &#39;n&#39; Roll will break your heart.</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://lavaoxsea.com/"/>
  <updated>2019-03-05T09:22:16.577Z</updated>
  <id>http://lavaoxsea.com/</id>
  
  <author>
    <name>paz</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>第四届阿里中间件性能挑战赛总结(复赛)</title>
    <link href="http://lavaoxsea.com/2018/10/24/%E7%AC%AC%E5%9B%9B%E5%B1%8A%E9%98%BF%E9%87%8C%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%80%A7%E8%83%BD%E6%8C%91%E6%88%98%E8%B5%9B%E6%80%BB%E7%BB%93(%E5%A4%8D%E8%B5%9B)/"/>
    <id>http://lavaoxsea.com/2018/10/24/第四届阿里中间件性能挑战赛总结(复赛)/</id>
    <published>2018-10-24T14:51:22.000Z</published>
    <updated>2019-03-05T09:22:16.577Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://code.aliyun.com/middlewarerace2018/queuerace2018?spm=5176.11409106.555.2.74c16668bKJEqg&amp;accounttraceid=10474bc7-3bc6-46b6-ad68-086faf849447" target="_blank" rel="noopener">复赛题目</a>的描述相对就简单了，但是题目难度就提升了好多……菜鸡如我已经顶不住了，还好有好多大佬打完初赛并不参加复赛了，没有丢人垫底……<br>这里我简单分享下我的思路，再介绍一下dalao们的解决方案……</p><h3 id="题意分析"><a href="#题意分析" class="headerlink" title="题意分析"></a>题意分析</h3><p>题目提供的信息如下：<br>内容：实现一个进程内的队列引擎，单机可支持100万队列以上。<br>校验程序分为三个阶段： 1.发送阶段 2.索引校验阶段 3.顺序消费阶段 </p><ol><li>各个阶段线程数在20~30左右 </li><li>发送阶段：消息大小在50字节左右，消息条数在20亿条左右，也即发送总数据在100G左右 </li><li>索引校验阶段：会对所有队列的索引进行随机校验；平均每个队列会校验1~2次； </li><li>顺序消费阶段：挑选20%的队列进行全部读取和校验； </li><li>发送阶段最大耗时不能超过1800s；索引校验阶段和顺序消费阶段加在一起，最大耗时也不能超过1800s；超时会被判断为评测失败。<br>至于具体的题目要求选手查看demo了解。</li></ol><p>总结一下，现在需要实现一个QueueStore的子类DefaultQueueStoreImpl。需要能够存储百万数量级的消息队列，验证时并发存和并发读，要求tps能够达到最大。需要实现的接口如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">QueueStore</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 把一条消息写入一个队列；</span></span><br><span class="line"><span class="comment">     * 这个接口需要是线程安全的，也即评测程序会并发调用该接口进行put；</span></span><br><span class="line"><span class="comment">     * 每个queue中的内容，按发送顺序存储消息（可以理解为Java中的List），同时每个消息会有一个索引，索引从0开始；</span></span><br><span class="line"><span class="comment">     * 不同queue中的内容，相互独立，互不影响；</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> queueName 代表queue名字，如果是第一次put，则自动生产一个queue</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> message message，代表消息的内容，评测时内容会随机产生，大部分长度在64字节左右，会有少量消息在1k左右</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">abstract</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(String queueName, <span class="keyword">byte</span>[] message)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 从一个队列中读出一批消息，读出的消息要按照发送顺序来；</span></span><br><span class="line"><span class="comment">     * 这个接口需要是线程安全的，也即评测程序会并发调用该接口进行get；</span></span><br><span class="line"><span class="comment">     * 返回的Collection会被并发读，但不涉及写，因此只需要是线程读安全就可以了；</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> queueName 代表队列的名字</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> offset 代表消息的在这个队列中的起始消息索引</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> num 代表读取的消息的条数，如果消息足够，则返回num条，否则只返回已有的消息即可;没有消息了，则返回一个空的集合</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">abstract</span> Collection&lt;<span class="keyword">byte</span>[]&gt; get(String queueName, <span class="keyword">long</span> offset, <span class="keyword">long</span> num);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>难点在于系统的限制，内存8g，其中JVM的堆内存限制为4g。此外还拥有一块 iops 1w 左右；块读写能力(一次读写4K以上) 在200MB/s 左右的超强性能ssd。</p><p>在demo中，有个测试类描述了测试逻辑：</p><ol><li>递增新增消息，取模后得到消息队列的序号，再向消息队列引擎发送序号和当前队列中消息数量，并记录每个消息队列的长度</li><li>随机挑选消息队列，获取它随机连续的十个值，比较其内容是否与索引的序号一致</li><li>与第二步类似，不过它会不断获取十个值直到队列中所有消息被读出。</li></ol><p>其中涉及到一些多线程分工的细节，不展开讲解了。题目禁止使用第三方库，可以看出要实现的逻辑还是很有难度的，也就是需要使用有限制的资源支持海量的消息及百万级的消息队列。</p><h3 id="解题"><a href="#解题" class="headerlink" title="解题"></a>解题</h3><p>需要设计一种方式能够高效的存储消息队列，一个很直观的思路是一个文件对应一个消息队列，但是这种方式创建的文件过多，超过操作系统的文件句柄上限。<br>总共要存储的消息为100G，我的想法是分比如200个文件去存储这些消息，那么每个文件的大小约为100M。存储用的文件越多，并发执行时被文件锁阻塞就越少，读写效率也会高一些，但是但是实际验证的测试表明多文件并没有优势，反而占用了过多的资源。<br>然后就是设计存储结构，使put和get尽量能够高效的并发执行。因为消息的数量太大，所以要对消息做索引，写入的时候同时写入索引，读取也是会依据索引读取。索引可以存在文件中，或者是直接保存在内存里。保存在文件中的话相当于再用一个二级索引去查找索引文件，这里我是直接把消息的索引存在内存中了。索引记录的是消息的开始位置，所以在消息文件中还需要记录消息长度。如果为每一条消息都建立一条索引占用过多空间肯定是不可行的，这里我的索引记录的是连续的几条消息的开始位置。put写消息时会等待几条消息的到来，满足长度后写入并记录返回的写入位置和写入消息占用的总长度。get读取时读取能够覆盖所需长度的几个索引记录的信息并从中获取所需消息序列。</p><p>下面描述一下我的实现，代码量其实很小……</p><ul><li>初始化DefaultQueueStoreImpl 创建FILE_NUM个文件。初始化messageListMap和queueMap两个ConcurrentHashMap，一个负责记录每个消息队列未写入的消息，另一个记录每个消息队列的索引。然后对于每个存储消息的文件，创建一个DataAccess对象。DataAccess是负责消息写入文件和读取的逻辑，之后讲解，索引使用一个POJO类Position来表示，拥有三个字段filename、index和size。</li><li>put 不断把消息添加到指定消息队列对应的list中，直到达到MSG_LIST_LEN（一个索引记录的消息量）。对这个list加锁，随机选择一个文件，使用对应的DataAccess对象将消息写入该文件，并把写入的位置、消息长度和文件名组成索引存到queueMap中。</li><li>get 使用queueName参数从queueMap获取能够覆盖offset到offset+size长度的索引列表，把每个索引对应的消息使用DataAccess全部取出来，从中间获取我们需要的部分返回。</li><li>flush 因为读写是两阶段进行的，在写结束后可能有些数据还在list或者buffer中，read之前会先触发一次flush方法。这个flush会把list中的数据使用DataAccess写入文件并调用DataAccess的flush方法。</li></ul><p>DataAccess也采用了一些特殊的设计，使用了<code>FileChannel</code>来负责读写文件。因为JVM限制为了4g，要利用剩余的4g空间可以使用堆外内存。通过ByteBuffer.allocateDirect来创建一个buffer，每个DataAccess都拥有一个这样的buffer。每次写入消息后，将消息写到buffer中去，当buffer满时再写入channel，重置buffer。读取则是通过channel的map方法从文件channel中映射一个MappedByteBuffer对象，在把消息通过消息长度解析出来。写入流和读取流是两个不同的channel，写入流通过append模式<code>FileOutputStream</code>获取，读取流通过r模式的RandomAccessFile获取。写入文件时要对文件加锁，读取则可以并发读。<br>次外，包含一个flush方法把buffer中的数据全部写入文件。</p><p>最后这套流程并不能跑出结果……因为4g内存爆了，直接抛出OutOfMemory错误。不过我当时调整本地测试代码的参数到题目要求是可以跑出结果的……所以一直没有看出问题在哪里，直到我有次错误的把锁加在put方法上，竟然跑出结果了……猜测是因为写入时间已经达到最大而消息还未全部写入，直接进入检索和校验阶段。最终tps为287266.3，就是这个结果勉强让我有个名次……实际上前40的团队已经有一百万的结果，而前十更是怒超2,000,000。其实可以简单算一下，4g内存对我这套流程肯定是不够用的。假设FILE_NUM为1000，MSG_LIST_LEN为50。也就是说索引的记录数为 2,000,000,000 / 50 等于 40,000,000条，一条索引所占内存大约为32bytes，总共约占1.28G。而list中消息的数量为1,000,000 * 50，乘以大小50 + 4bytes，总共约占2.7G。再加上1,000,000个队列名，此时加起来肯定已经超过4g了。我对JVM不是很熟，应该还是少算了一些内存消耗，赛后我感觉主要的一个问题是没有做消息的压缩和解压，压缩过的消息应该能省下不少内存。</p><h3 id="赛后"><a href="#赛后" class="headerlink" title="赛后"></a>赛后</h3><p>事实上这次复赛我做的稀烂……而且时间比较紧也没法临时去学，只能赛后再总结学习，还是有很多收获的。</p><p>java IO: JavaAPI中存在三种方式，基于字节流的方式（IOStream），基于buffer的方式（FileChannel），基于Mmap（MapppedByteBuffer）。基于字节的方式是最原始的方式，效率不高。而使用channel可以以buffer为块进行IO操作，和操作系统对磁盘的IO非常相似，此外buffer可以申请堆外内存，减少gc次数。而且可以避免内存的堆内堆外复制。而mmap则会在文件大小为1-1.5G的情况下发挥出最佳性能，它是基于虚拟内存将对文件的操作映射到磁盘上。但是缺点是释放较为复杂而且其使用的虚拟内存不好控制。<br>此外，通过使用Unsafe的方式，java也可以越过page cache来直接操作文件，也就是directIO。<br><img src="linux-io.png" alt="linux-io"></p><p>ssd: ssd需要以4k字节的整数倍进行IO才能获取最大的性能。比赛提供的ssd的性能参考：<br><img src="ssd.png" alt="ssd"><br>因此，这里为了达到最高性能，至少应该以16kb为buffer大小单位进行磁盘读写。</p><p>异步读写：在程序中IO不应该阻塞逻辑线程。这也是很关键的一点。这里可以应用一个生产者消费者魔性，通过一个blockingqueue在异步IO线程和逻辑线程进行交互。</p><p>ThreadLocal：在程序中我因为使用了大量的文件从而为每个文件分配了一个文件操作工具类并分配directBuffer。事实上，少量文件满足需求，并且把buffer存在ThreadLocal中可以方便得管理。</p><p>gc 优化：能用数组的地方不要用 List。尽量减少小对象的出现，可以用数组管理基本数据类型，小对象对 gc 非常不友好，无论是初赛还是复赛，Java 比 Cpp 始终差距一个垃圾回收机制。必须保证全程不出现 full gc。</p><p>在读取整个队列时，通过预读减少IO次数可以显著提高性能。也就是模拟page cache的行为。page cache在内存有限时分配会受影响。</p><p>在读写文件时，顺序读写快于随机读写。因此在读写文件时需要加锁，确保是按顺序写入文件，不会导致文件空洞和跳读以达到最优的性能。但是加锁的顺序读写无法打满磁盘IO（iops）。因此需要进行文件分区，分多少合适呢？文件多了，锁冲突变降低了；文件太多了，碎片化太过严重，单个文件的值太少，缓存也就不容易命中。</p><p>性能优化的万金油</p><ul><li>Batch<ul><li>增加单次IO的吞吐量，目标打满磁盘吞吐</li></ul></li><li>Pipeline<ul><li>提交刷盘任务流水线化</li></ul></li><li>Buffer/Cache<ul><li>写数据，先放buffer，再批量写</li><li>读数据，先放cahce，减少IO</li></ul></li><li>Non-Block<ul><li>异步刷盘/读盘</li></ul></li></ul><p>ssd 4k<br>写：<br>批次/消息区块<br>单独的IO线程<br>读：<br>缓存 LRU（最近最小使用）<br>异步预读</p><p>msgBatch:1k<br>pdkblock:64k -&gt; 存储单元<br>blockpool:3G -&gt; ConcurrentLinkedQueue 调用线程写入，IO线程寻找写满的落盘 （生产者/消费者）</p><p>压缩 ascci 前两位丢弃<br>预读 把40000个block放入Cache，通过blockId判断</p><p>分析<br>写 2e9 put 100G<br>随机读 1e6 get 500M<br>顺序读 2e8 get 10G<br>磁盘 IOPS 10000 吞吐 200mb/s</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://code.aliyun.com/middlewarerace2018/queuerace2018?spm=5176.11409106.555.2.74c16668bKJEqg&amp;amp;accounttraceid=10474bc7-3bc6
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>第四届阿里中间件性能挑战赛总结(初赛)</title>
    <link href="http://lavaoxsea.com/2018/09/13/%E7%AC%AC%E5%9B%9B%E5%B1%8A%E9%98%BF%E9%87%8C%E4%B8%AD%E9%97%B4%E4%BB%B6%E6%80%A7%E8%83%BD%E6%8C%91%E6%88%98%E8%B5%9B%E6%80%BB%E7%BB%93(%E5%88%9D%E8%B5%9B)/"/>
    <id>http://lavaoxsea.com/2018/09/13/第四届阿里中间件性能挑战赛总结(初赛)/</id>
    <published>2018-09-13T11:01:45.000Z</published>
    <updated>2019-03-02T06:38:01.321Z</updated>
    
    <content type="html"><![CDATA[<p><img src="logo.png" alt=""><br>上个学期抽空打了一下<a href="https://tianchi.aliyun.com/programming/introduction.htm?spm=5176.100066.0.0.6acd33afBcahZs&amp;raceId=231657" target="_blank" rel="noopener">阿里中间件的比赛</a>。作为少见的程序设计竞赛，还是有些收获的。最后的成绩如下：</p><p><img src="result.png" alt=""><br>总体说起来马马虎虎吧，感觉和排行榜顶尖选手的差距还是很大的。后文也会说到他们的技术思路。</p><h3 id="题意分析"><a href="#题意分析" class="headerlink" title="题意分析"></a>题意分析</h3><p><a href="https://code.aliyun.com/middlewarerace2018/docs?spm=5176.11409106.555.1.627f6668H7cbDv" target="_blank" rel="noopener">初赛题目</a>非常长，而且复杂。这是第一个难关，要有耐心好好审题，理解要做什么。这里再简单描述下：<br>目标是实现一个Service Mesh，也就是在不改变服务本身的情况下，通过添加以 proxy 或 sidecar 形式部署的 Agent，实现服务的治理（服务注册、负载均衡等）。通过这种方式，所有进出服务的流量都会被Agent拦截，因此可以做到协议的转换，够使得基于不同技术框架和通讯协议建设的服务也可以实现互联互通。<br>service-mesh示例：<br><img src="service-mesh-architecture.png" alt="service-mesh-architecture"></p><p>题目系统架构如下：<br><img src="system-architecture.png" alt="system-architecture"><br>图中所有的服务都运行在Docker容器中。流程是 Consumer 通过 Consumer-Agent 在 etcd 注册服务，通过Dubbo协议进行RPC。Provider 会通过 Provider-Agent 在 etcd 中查找已经注册的 Consumer 服务并向其 Agent 发送RPC的请求。此外，Provider 还向外界暴露RPC调用接口提供调用。Consumer 的调用要做到负载均衡。以上，需要达到最高的qps。</p><p>初赛最nice的地方是提供了一个Demo，让我们这些没见过上面很多技术的人可以大致先了解一下。事实上，我的大部分工作最开始都是基于这份demo。</p><p><a href="https://code.aliyun.com/middlewarerace2018/agent-demo" target="_blank" rel="noopener">Agent示例</a><br><a href="https://code.aliyun.com/middlewarerace2018/services" target="_blank" rel="noopener">Provider 及 Consumer 服务</a></p><p>其中官方提供的 Provider 和 Consumer 是不可以被修改的。它们都是基于Spring-boot的，逻辑较为简单。其中 Provider 提供了Dubbo的RPC服务，暴露了一个IHelloService接口：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">IHelloService</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">hash</span><span class="params">(String str)</span> <span class="keyword">throws</span> Exception</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>实现的hash方法如下<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(String str)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> hashCode = str.hashCode();</span><br><span class="line">    logger.info(++count + <span class="string">"_"</span> + hashCode);</span><br><span class="line">    sleep(<span class="number">50</span>);</span><br><span class="line">    <span class="keyword">return</span> hashCode;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>每次调用线程睡眠50ms，模拟运行消耗。该服务需要使用Dubbo协议调用，除此以外不需要其他的Dubbo知识。</p><p>Consumer 就像一个常见的Spring-boot服务，提供了一个控制器。随机生成了1024长度字符串。使用AsyncHttpClient异步地向 Provider 进行RPC的请求，得到返回值并和该字符串的hash值做比较。如果相同则返回值为OK的ResponseEntity，不同则返回值为ERROR的ResponseEntity。示例中还用到了SpringMVC中的异步返回，也就是返回DeferredResult实例。当值被赋给该实例时才会返回。此外AsyncHttpClient库提供了发送异步请求而不阻塞线程的方式，可以学习一下它的API，很实用。具体的函数如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/invoke"</span>)</span><br><span class="line"><span class="function"><span class="keyword">public</span> DeferredResult&lt;ResponseEntity&gt; <span class="title">invoke</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    String str = RandomStringUtils.random(r.nextInt(<span class="number">1024</span>), <span class="keyword">true</span>, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    String url = <span class="string">"http://127.0.0.1:20000"</span>;</span><br><span class="line"></span><br><span class="line">    DeferredResult&lt;ResponseEntity&gt; result = <span class="keyword">new</span> DeferredResult&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    org.asynchttpclient.Request request = org.asynchttpclient.Dsl.post(url)</span><br><span class="line">            .addFormParam(<span class="string">"interface"</span>, <span class="string">"com.alibaba.dubbo.performance.demo.provider.IHelloService"</span>)</span><br><span class="line">            .addFormParam(<span class="string">"method"</span>, <span class="string">"hash"</span>)</span><br><span class="line">            .addFormParam(<span class="string">"parameterTypesString"</span>, <span class="string">"Ljava/lang/String;"</span>)</span><br><span class="line">            .addFormParam(<span class="string">"parameter"</span>, str)</span><br><span class="line">            .build();</span><br><span class="line"></span><br><span class="line">    ListenableFuture&lt;org.asynchttpclient.Response&gt; responseFuture = asyncHttpClient.executeRequest(request);</span><br><span class="line"></span><br><span class="line">    Runnable callback = () -&gt; &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 检查返回值是否正确,如果不正确返回500。有以下原因可能导致返回值不对:</span></span><br><span class="line">            <span class="comment">// 1. agent解析dubbo返回数据不对</span></span><br><span class="line">            <span class="comment">// 2. agent没有把request和dubbo的response对应起来</span></span><br><span class="line">            String value = responseFuture.get().getResponseBody();</span><br><span class="line">            <span class="keyword">if</span> (String.valueOf(str.hashCode()).equals(value))&#123;</span><br><span class="line">                result.setResult(ok);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                result.setResult(error);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    responseFuture.addListener(callback, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>至此，题意也基本清晰了。我们需要实现的是两个Agent即 Consumer-Agent 和 Provider-Agent。其中 Consumer-Agent 负责接收 Consumer 的http请求，并通过 etcd 查找 Provider-Agent 服务，从而向 Provider-Agent 发送请求并将结果返回给Consumer。而 Provider-Agent 负责向 etcd 注册，接收来自 Consumer-Agent 的请求，并向 Provider 发送dubbo请求，返回结果给 Consumer-Agent。<br>题目页面上有这么一个展示流程的表格：</p><table><thead><tr><th>通讯环节</th><th>序列化协议</th><th>远程通讯协议</th><th>备注</th></tr></thead><tbody><tr><td>Client =&gt; Consumer</td><td>（无参数传递）</td><td>HTTP</td><td></td></tr><tr><td>Consumer =&gt; Consumer Agent</td><td>FORM</td><td>HTTP</td><td></td></tr><tr><td>Consumer Agent =&gt; Provider Agent</td><td>FORM</td><td>HTTP</td><td>可根据需要自定义</td></tr><tr><td>Provider Agent =&gt; Provider</td><td>JSON</td><td>DUBBO</td><td></td></tr><tr><td>Provider =&gt; Provider Agent</td><td>JSON</td><td>DUBBO</td><td></td></tr><tr><td>Provider Agent =&gt; Consumer Agent</td><td>TEXT</td><td>HTTP</td><td>可以根据需要自定义</td></tr><tr><td>Consumer Agent =&gt; Consumer</td><td>TEXT</td><td>HTTP</td><td></td></tr><tr><td>Consumer =&gt; Client</td><td>TEXT</td><td>HTTP</td><td></td></tr></tbody></table><p>题目中还有一个设定，总共有三个能力不同的 Provider 提供Dubbo的RPC服务，分别为small medium large。因此。我们也需要提供分别对应的 Provider-Agent。Provider 能力不同体现在占用系统资源百分比不同，比例为1:2:3。</p><h3 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h3><p><a href="https://code.aliyun.com/middlewarerace2018/benchmarker" target="_blank" rel="noopener">官方配置教程</a><br>比赛所用到的环境都是基于Docker的，因为整体环境较为复杂而且需要做到能够在本地评测分数，当时搭建环境也花了一个晚上，所以这里也稍微介绍一下。<br>系统运行时存在两个角色，一个是施压机，另一个是被压机。可以简单的理解为，被压机用于运行我们的程序，而施压机用于向我们的程序提供输入并接收输出，从而计算qps做为分数。<br>系统简单起见，设置施压机寻找被压机的方式是，修改施压机的host文件，将被压机的域名修改为 shuke.&lt;host-name&gt;。host-name为施压机的主机名。</p><h6 id="被压机"><a href="#被压机" class="headerlink" title="被压机"></a>被压机</h6><p>被压机在测试过程中，被需要被施压机启动相应的环境。因此需要在相应的用户目录下创建.passwd文件，并在其中配置密码。此外，被压机需要安装好Docker环境。</p><h6 id="施压机"><a href="#施压机" class="headerlink" title="施压机"></a>施压机</h6><p>施压集需要配置python运行环境以及pipenv以运行测试脚本。此外还需要配置wrk，用于压力测试。</p><h6 id="测试流程"><a href="#测试流程" class="headerlink" title="测试流程"></a>测试流程</h6><p>首先启动一个mock server。它是使用python的BaseHTTPRequestHandler和HTTPServer实现的，作用是在POST请求时返回返回一个带有docker镜像路径的JSON串，用于配置测试task。<br>还需要配置一下测试脚本里的bootstrap.conf,具体见官方教程。</p><p><code>pipenv run python bootstrap.py -p &lt;prefix&gt;</code> 启动测试。prefix为hostname前缀。</p><p>整套测试是基于自动化的python脚本，线上环境应该和线下一样。</p><ul><li><p>bootstrap<br>入口，读取logging.yml作为全局<code>logging</code>的配置，输出到console。事实上线上测试是写到文件的。<br>使用<code>argparse</code>读取命令行的<code>prefix</code>参数和配置文件名，默认为bootstrap.conf。通过<code>configparser</code>将配置文件读入<code>Configuration</code>实例<code>config</code>中。<br>将<code>config</code>传入<code>TaskAgent</code>。其作用主要是拉取需要执行的测试任务，因为这里是线下环境，所以我们的任务由前面提到的Mock Server提供。将一些身份信息组为payload，由<code>requests</code>发送post请求Server的url。信息和url都在bootstarp.conf中配置。返回的信息保存为一个<code>Task</code>实例，保存的主要是队伍ID，任务ID，仓库路径，镜像路径，Docker仓库的用户名和密码。（提交代码时也需要上传打包好的镜像，不过阿里云提供自动构建）本地测试的话这些都不需要。<br>以上基本配置完成后，将<code>task</code>和<code>config</code>传入<code>Workflow</code>开始测试流程。</p></li><li><p>workflow<br>初始化中生成<code>Workspace</code>实例，包含<code>local</code>和<code>remote</code>两个成员，分别代表施压机和被压机的工作目录，并且包含属性为相应的路径。<br>随机生成一个五位数的salt。</p><ol><li>__lock_local_workspace()<br>创建local(施压机)的目录环境。尝试创建.lock文件，成功直接返回，失败抛出异常。</li><li>__generate_dockerpwd_file()<br>尝试将task中的docker密码写入.dockerpwd文件，成功返回，失败抛异常。</li><li>__create_remote_task_home()<br>将创建remote(被压机)目录的shell脚本写到一个字符串中，调用<code>__run_remote_script</code>执行。<code>__run_remote_script</code>主要是将脚本用ssh组合起来，之后调用<code>__run_script</code>执行。而<code>__run_script</code>是通过<code>subprocess.Popen</code>的<code>communicate</code>方法执行脚本，获取outs, errs。通过<code>Popen</code>的<code>returncode</code>获取返回值。回到原方法，如果返回值不为0，抛出异常。</li><li>__lock_remote_task_home()<br>和上一个方法类似，不过把shell脚本改为创建.lock文件。</li><li>__upload_dockerpwd_file()<br>同样是内容为一个scp的shell脚本，不过调用的是<code>__run_local_script</code>，这个方法直接调用<code>__run_script</code>在本地执行脚本。</li><li>__docker_login()<br>被压机调用的是docker login的shell脚本，此外docker仓库的密码之前已经被存到文件中，读取之后删除。</li><li>__pull_docker_images()<br>远程执行脚本，读取之前保存在~/.passwd位置的用户密码，sudo调用docker pull拉取我们上传的镜像、etcd镜像、ncat镜像</li><li>__check_signatures()<br>上传的镜像在构建时会拉取provider consumer 和 docker-entrypoint.sh，需要确保未被修改。远程执行脚本，读取.passwd以root权限调用docker run 执行sha256sum和之前算好的值比较。不一致则返回错误码，抛出异常。</li><li>__create_docker_network()<br>远程执行创建docker network的脚本。子网为10.10.10.0/24，网关为10.10.10.1，子网掩码为255.255.255.0。</li><li>__start_etcd()<br>远程执行启动docker etcd的脚本，从config中指定etcd的资源等参数，网络为刚才创建的docker network。在TaskHome目录下创建etcd文件夹，里面创建logs文件夹保存日志文件，启动docker时映射相应位置。此外，docker run还指定了cidfile保存在etcd文件夹内。<br>然后使用ncat镜像连接刚才创建的etcd，尝试MAX_ATTEMPTS次，每次失败sleep一定时间，成功后结束，失败则返回错误码。</li><li><p>__start_providers(salt)<br>过程同上， 不过是启动三个不同规格的provider，提供的是provider镜像需要的参数。ncat连接也是相似的过程。此外还需要将salt值传给启动的docker，但是在docker内entrypoint脚本中并没有用到这个值。</p><p>这里再讲解一下provider及consumer的docker镜像构建及启动过程，也就是Dockerfile。</p><ul><li>复制项目文件到workspace/agent</li><li>将work/agent设为工作区</li><li>mvn clean package</li><li>拉取provider和consumer的jar包复制到指定目录，将项目打成的jar包也复制到目标目录</li><li>拉取docker-entrypoint.sh到目标位置，它的作用是启动Provider和Consumer</li><li>将start-agent.sh复制到目标位置，它的作用是按照我们配置的参数启动Agent</li><li>创建/root/logs为日志目录</li><li>暴露8087端口</li><li>将docker-entrypoint.sh设为ENTRYPOINT<br>docker-entrypoint.sh及start-agent.sh都是简单的脚本文件，docker-entrypoint.sh执行结束后会执行start-agent.sh。都是<code>java -jar</code>方式启动相应的服务，日志保存在镜像里指定的位置，其他主要是type和端口的配置，还有分配的内存大小。docker-entrypoint.sh配置了三种provider和consumer的内存大小，而start-agent.sh则是需要我们手动配置的。</li></ul></li><li><p>__start_consumer(salt)<br>过程同上，启动镜像参数type为consumer。</p></li><li><p>__warmup_then_pressure()<br>热身然后压力测试。本地执行shell脚本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wrk -t&#123;threads&#125; -c&#123;connections&#125; -d&#123;duration&#125; -T&#123;timeout&#125; \</span><br><span class="line">                --script=./benchmark/wrk.lua \</span><br><span class="line">                --latency http://&#123;hostname&#125;/invoke</span><br></pre></td></tr></table></figure><p>使用partial，传入wrk_timeout和hostname。<br>对于不用的压力，使用相应的threads connections duration。本地测试脚本的线程数为2，连接数分别为64/128/256，测试60s。<br>–latency会输出结果，–script制定了wrk.lua脚本，指定了done函数，规定了输出的格式，包挎QPS，平均响应时间，最大最小响应时间等。通过HTTP响应码来判断请求是否成功（200/300）。<br>然后使用正则表达式从输出的结果中获取每次的QPS。</p></li><li>__stop_services()<ul><li>__stop_consumer()</li><li>__stop_providers()</li><li>__stop_etcd()<br>步骤类似，先从相应的目录读取cidfile，获取容器的cid。调用docker logs，将输出重定向到之前映射容器内部用于保存日志的位置。之后stop &amp; rm</li></ul></li><li>__cleanup()<ul><li>__remove_docker_image() 使用镜像名称做docker rmi操作。我们自己打包上传的镜像名称在task里获取。</li><li>__unlock_remote_task_home() 删除被压机工作目录下的.lock文件</li><li>__unlock_local_task_home() 删除施压集工作目录下的.lock文件</li></ul></li><li>__collect_data()<ul><li>__compute_result() 计算之前得到所有QPS中的最大值作为结果</li><li>__download_logs() 远程执行shell脚本，叫工作目录的所有文件都打包成.tar.gz，保存在当前目录的上一级，文件名为logs。之后本地执行scp脚本将这个文件复制到本地工作目录，将teamId/taskId写入当前目录的.osspath文件。<br>以上基本上就是完成的工作流程，最终如果中途抛出了异常，则返回qps为-1的json串，否则用best_qps组成一个json返回。boostrap得到这个结果后用TaskAgent将结果上传到目标url。</li></ul></li></ol></li></ul><p>整个流程是自动化的，当时在比赛时没有时间细看，现在赛后分析才认真学习了一下，感觉虽然功能并不复杂但还是挺厉害的，而且日志的配置很到位，错误的排查以及流程的确认都很清晰。</p><h3 id="Agent"><a href="#Agent" class="headerlink" title="Agent"></a>Agent</h3><p>现在我们回到题目本身，已经清楚的是Provider和Consumer的输入输出和程序最终的目标，需要实现的是Agent（一个Consumer-Agent和三个Provider-Agent），Agent的代码只有一份，会根据启动的参数-Dtype判断是Consumer还是Provider。<br>Demo中已经为我们实现了一个Agent的样例，是可以跑通的，借此也可以帮助理解Agent具体实现的功能和细节。因为代码稍微有点多，只挑重点说一下流程。<br>这个Agent和之前的Rrovider和Consumer类似，使用了Spring-boot来处理请求和响应。</p><p>使用<code>HelloController</code>作为程序的入口，定义了一个<code>EtcdRegistry</code>成员用于服务注册和服务发现。<code>EtcdRegistry</code>是一个工具类，使用初始化时传入ip地址。etcd是一个基于Go的高可用强一致性的服务发现存储仓库，<a href="https://linux.cn/article-4810-1.html" target="_blank" rel="noopener">这里</a>有一篇介绍，不展开讨论了。etcd在系统中负责服务的注册与发现并提供负载均衡的能力，完成题干中描述的两项任务。实际上我们只需对样例稍加修改就可以直接使用代码。不过etcd的负载均衡能力是基于多个etcd节点的，这里我们还是需要自己实现。<br><code>EtcdRegistry</code>中主要使用了coreos的jetcdAPI，通过传入IP来创建endpiont，然后创建lease。它拥有超时时间和唯一ID。之后启动一个线程向etcd发送心跳包，保持连接。通过系统参数判断是Provider还是Consumer（Agent），如果是Provider则进行服务注册，构造键值并传入etcd。键由预定义头、服务名、IP和端口组成，值为空。如果为Consumer则会用预定义头和服务名去查找所有满足的键值对，用获取到的IP和端口构造endpoint列表返回。</p><p>回到Controller，仅提供了一个接口invoke。传入的dubboRPC所需的参数。在invoke内部会根据系统参数判断Provider和Consumer，并依此调用相应的方法。接下来按流程讲解一下（先Consumer再Provider）</p><ul><li>Consumer的流程：使用okhttp库向之前通过etcd查找出来的endpoint以随机选择一个的方式发送请求，并等待响应返回。</li><li>Provider的流程：生成一个RpcClient实例，用于向Dubbo发送请求。RpcClient的invoke方法中构造了一个Request的POJO实例，设置了一些Dubbo请求首部的字段，该程序中意义不大不赘述，然后创建了一个PRCInvovation的POJO实例，把方法的参数（Dubbo的请求体）设置到该实例中。使用<code>DataArrayOutputStream</code>和JsonUtil将PPCInvocation作为JSON的byte数组设为Request的一个属性data（Provider要求）。此外Request还拥有一个成员id，使用<code>AtomicLong</code>保证自增，唯一标识一个对象。现在我们有构造好的Request实例了。<br>* 接下来是示例中的重点：<br>首先我们应该明确的是接下来我们需要做的是向Dubbo发送RPC请求并接受结果，此时应该使用的是Dubbo协议（题目附录中有简要介绍），在这里使用了一个很重要的第三方库，Netty。在RpcClient中有一个成员ConnectManager，完成了初始化bootstarp的操作。在我们的invoke操作中从ConnectManager中获取了channel的单例（provider-agent和provider是一对一的关系），并把request写入其中。之后，我们需要获取请求结果，这里也有点意思。实例提供了一个RpcRequestHolder类，里面有一个<code>ConcurrentHashMap</code>成员并提供了get set方法，在发送请求前，创建了一个RpcFuture实例用于接收返回的结果然后把唯一的请求id作为键，RpcFuture作为值存到RpcRequestHolder中去。netty在接收到返回后会通过reponse中携带的requestID来找到对应的RpcFuture并把内容写到其中。RpcFuture中还包含了一个RpcResponse实例，等同于响应的byte数组。在发送完向channel中写入请求后，invoke方法会调用RpcFuture的get方法等待响应的结果。在RpcFuture中有一个<code>CountDownLatch</code>值为1的实例，在netty写入reponse后会将其减一。get方法会调用<code>CountDownLatch</code>的<code>await</code>方法等待它的值为0并返回结果。</li></ul><p>至此，一套完整的流程已经结束，除了一个部分，netty处理dubbo协议的编解码，处理响应（因为这里的netty作为一个客户端）。也即是<code>ChannelInitializer</code>的内容。一共用到三个类，DubboRpcEncoder用于编码，DubboRpcDecoder用于解码，RpcClientHandler用于处理响应。</p><ul><li>DubboRpcEncoder 继承了<code>MessageToByteEncoder</code>类， 在<code>encode</code>方法中把message(request)写到buffer(ByteBuf)中。包括两部分：写入首部，写入消息体。过程如下：记录当前buffer的index，把buffer的index设为当前index+首部length，写入json序列化后的信息体，然后重置index并写入首部。其中JSON序列化是题目中dubbo要求的，使用了阿里的<code>SerializeWriter</code>和<code>JSONSerializer</code>序列化对象。</li><li>DubboRpcDecoder 与encoder类似，用于解码dubbo协议，获取消息体。不过这里有个常用操作，检查buffer可读字节的长度，如果每有超过首部长度或者超过了但是没有超过整个消息的长度（通过首部内的长度字段判断），会重置<code>ByteBuf</code>读取的index。直到没有可读数据退出。解码后，会将消息体封装为<code>RpcResponse</code>，交给接下来的handler处理。</li><li>RpcClientHandler 通过RpcResponse内的id，从之前保存RpcFuture的RpcRequestHolder中获取对应的RpcFuture，调用done方法来去除<code>CountDownLatch</code>的锁，返回dubboRPC的结果。<br>示例的qps线上测试的结果在900左右。</li></ul><p>接下来的内容是我修改这个示例的过程：</p><h6 id="version-1"><a href="#version-1" class="headerlink" title="version 1"></a>version 1</h6><p>首先想到可以修改的是Agent Consumer请求Agent Provider的OKHttp这块的内容。Consumer发送请求使用的是AsyncHttpClient，要在有限的资源限制情况下获取尽可能高的资源利用率，Agent也可以使用这种方式，这一步操作我在比赛中并没有做……我一开始就去把agent之间的通讯替换成了netty的方式。</p><p>示例中agent与consumer交互是我第一次接触netty，这种异步的交互方式刷新了我的认知，感觉这种方式很强无敌。于是我觉得使用netty来替代agent之间的spring boot会显著的提高qps。但其实并不是这样，当时还没有理解netty的异步特性。我做的操作就是模仿示例中netty与dubbo交互，不过channelpipline内部的内容修改了。</p><p>分为客户端和服务端简要讲解下，客户端是consumer-agent，服务端是provider-agent。客户端把使用okhttp发送请求更换为netty客户端发送请求。创建了一个ConsumerAgentClient类，因为要发送的是dubbo RPC的相关参数，而且后面在服务端会把这些参数组装为RpcInvocation，索性我直接就在客户端直接将对象封装好，之后服务端直接传递就行。这里我也和实例一样是通过RPCFuture阻塞直到数据返回（事实上这里就是性能提升的关键）…… ConsumerAgentClient会使用AgentConnectManager获取channel，AgentConnectManager管理了netty客户端的创建和管理。这里我又照抄了示例中的ConnectionManager……也就是说我的consumer-agent只会和一个provider-agent建立连接😂</p><p>不过这里我并没有直接使用实例中的ByteToMessageDecoder作decoder的基类，而是使用了LengthFieldBasedFrameDecoder。实例中provider需要不断去判断数据包的长度，这些工作完全可以由LengthFieldBasedFrameDecoder替我们完成。需要设置的参数如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MAX_FRAME_LENGTH = 4 * 1024; //最大帧长度</span><br><span class="line">LENGTH_FIELD_LENGTH = 4; //长度字段长度</span><br><span class="line">LENGTH_FIELD_OFFSET = 0; //长度字段距离帧头部偏移量</span><br><span class="line">LENGTH_ADJUSTMENT = 0; //长度调整量（是否要去掉头部长度，取决于长度字段的计算方式）</span><br><span class="line">INITIAL_BYTES_TO_STRIP = 0; // 丢弃首部的字段长度，比如解析出来没有用处的首部可以直接丢弃</span><br></pre></td></tr></table></figure></p><p>这里decode解析的帧格式为 长度 + requestId + 内容数据。之后通过requestId去holder中获取future中断阻塞。<br>服务端的内容就相对简单一些，同样通过decode来解析得到客户端发送的requestId和RpcInvocation对象，去holder中按requestId存储RpcFuture。在decode之后服务端还有一个inboundhandler负责处理业务逻辑。这里就是执行之前agent-provider在controller中的逻辑。<br>当然最后这个方式最终跑出来的结果惨不忍睹……qps大约就100……因为整个系统阻塞的太严重，原本基于spring-boot的bio还是一个请求对应一个线程，现在全部阻塞在一个线程上了。</p><h6 id="version-2"><a href="#version-2" class="headerlink" title="version 2"></a>version 2</h6><p>首先把consumer-agent请求provider-agent的channel由一个单例channel改为按hostIP:channel的键值对存到map中……解决了这个显而易见的bug。<br>虽然阻塞问题没解决，不过我还是在这里做了一个小改进，在provider-agent decode之后的AgentServerHandler中，原本是执行在线程中阻塞的逻辑，我把这段逻辑封装到一个Runnable中，然后提交到一个初始化时创建好的线程池中去执行，感觉这里有点Reactor模式的意思。这种方式一定程度上提高了provider-agent的利用率，这种情况下我的qps达到了1400。</p><h6 id="version-3"><a href="#version-3" class="headerlink" title="version 3"></a>version 3</h6><p>这个时候排行榜前100已经是5000左右的水平，我的代码有一些很重要的地方有问题，我终于意识到<code>CountDownLatch</code>就是万恶之源。之前对异步操作的理解不深，现在再回顾一下现有系统，consumer-agent中netty客户端发送请求，之后阻塞，等待服务端的响应。provider-agent的netty服务端收到请求后，在最后一个inboundhandler中使用netty客户端向provider发送请求，之后阻塞等待provider返回结果并向consumer-agent返回结果。</p><p>在异步执行的过程中，无意义的阻塞会耗费大量系统资源。因此这个版本主要解决的就是这个问题。让我们先解决后一个阻塞。首先我们不再使用RPCFuture及其内部的<code>CountDownLatch</code>，这里的思想是，我们不再等待数据的返回，而是当数据返回后回调响应的逻辑。也就是provider向provider-agent返回数据后，我们不等待这个数据的到达再返回给consumer-agent，而是直接执行下一步操作。代码中provider-agent最后得到返回数据是在AgentServerHandler类中，我们要在这里执行返回给consumer-agent的回调操作，即在provider-agent与consumer-agent交互的channel中写入数据。因为题目中provider-agent只会对应一个consumer-agent，所以我们可以在provider-agent中保存他们建立的channel。我把这个channel放在了ChannelHolder中，保证AgentServerHandler对其的访问。</p><p>接下来处理前一个阻塞，也就是consumer-agent收到provider-agent返回的数据，要返回给consumer。因为这里consumer-agent还是用spring-boot处理http请求，因此需要一些特殊的技巧。在Spring3.0后有了异步返回数据的概念，通过<code>DeferredResult</code>实现，具体可以自行查阅资料。在controller中，直接返回<code>DeferredResult</code>实例，等到它的内容被设置，才会回调执行返回数据，整个过程也是异步的不会产生阻塞。这样需要改造的阻塞操作就容易实现了，在consumer-agent中的netty客户端接受返回的AgentClientHandler中设置<code>DeferredResult</code>对象的内容就可以。这里还涉及到一个如何寻找到这个<code>DeferredResult</code>对象的问题，我的解决方案是：每次请求会用<code>AtomicLong</code>设置一个自增不重复的id来唯一标识一次请求，同时对应一个<code>DeferredResult</code>对象。每次创建<code>DeferredResult</code>对象时将其存到一个map中，键为id。之后的过程中发送请求和返回响应都携带这个id，最终就能通过这个id找到<code>DeferredResult</code>对象。<br>线上测试证明这种方式是行之有效的，qps首次突破4k。</p><h6 id="version-4"><a href="#version-4" class="headerlink" title="version 4"></a>version 4</h6><p>虽然spring-boot的异步方式确实性能不差，但是如果consumer-agent使用一个netty服务端来用更加纯粹的异步方式处理响应，可以更加高效的利用资源。此时spring-boot已被弃用，程序运行时会根据参数启动响应的netty服务端。<br>这里consumer-agent中的netty服务端要处理http请求，所以channelpipeline需要做相应调整，使用了<code>HttpServerCodec</code>,<code>HttpObjectAggregator</code>。这些类可以方便的帮我们将http报文中的内容封装成<code>FullHttpRequest</code>对象，传递给我自己实现的HttpConsumerHandler。经过字符串处理可以获得所需的rpc参数值，以上完成了原本由springmvc负责的部分。这里的netty服务端还有一点不同的是他要处理的连接的数量不再是1而是客户端的数量。以前保存deferredresult实例的map，现在需要保存channel对象，使之后的consumper-agent中的netty客户端可以异步向channel中写入响应。当然编码为http报文的工作还是交给<code>HttpClientCodec</code>完成的。<br>这个版本的效果差不多进入200名的及格线，在配置了一下相关参数后qps可以达到5400。</p><h6 id="version-5"><a href="#version-5" class="headerlink" title="version 5"></a>version 5</h6><p>既然整体流程已经是纯异步了，那可以提升的都是细节内容了。除了一个之前一直忽略的东西，provider-agent的负载均衡处理。在这之前，一直依靠的是轮询provider-agent来发送请求，这里我的想法是依据当前provider-agent的负载情况来发送请求。这里我考虑的负载情况可以用每个provider-agent还没有处理完的请求数量来表示。而每次我们都给其一个全局唯一的id，之前的版本我们是使用这个id来对应consumer和consumer-agent交互使用的channel，每次处理完从map中去除。如果我们能够把这个对应的map拆分为三个，每个provider-agent拥有一个，通过统计map键的数量就可以得到当前provider-agent处理的负载。发送请求时直接把请求发送给负载最小的agent即可。（不过现在回想由于agent的处理能力资源并不相同，可能这样方式还不是最优解）<br>稍微讲解一下具体的实现。负责发送请求的ConsumerAgentClient类持有一个map，键为host值为map对象（键为requestId，值为channel），分别对应不同provider-agent。初始化与每个provider-agent连接时，传入对应的channel，最终传入到负责异步写给consumer响应的AgentClientHandler，再写操作完成后会从map中去除requestId。每次发送请求会先检查每个map键的数量，取最小的向其中插入requestId和channel。<br>最终这个版本的效果提升并没有想象的大，qps为5600。</p><h6 id="version-6"><a href="#version-6" class="headerlink" title="version 6"></a>version 6</h6><p>其实到了这个时候我已经想不到什么改进了，做了很多失败的尝试，最终还是在有个不大不小的改进。查询了许多netty资料后，偶尔了解到有个叫做protobuf的序列化方式，比java自带的序列化方式快很多。netty的操作中有把对象写入成字节序列的，所以我想用protobuf来改进试一下。这里需要序列化的只有从consumer-agent向provider-agent发送的AgentRequest(id+RPCInvocation)对象，其他传输的都是byte数组。使用protobuf创建了一个ProtoRequest.java文件用来代表AgentRequest这个对象。在ConsumerAgentClient中sendRequest方法把创建ProtoRequest并写入channel，并把consumer-agent原本继承<code>MessageToByteEncoder</code>的CustomerAgentEncoder替换为<code>ProtobufVarint32LengthFieldPrepender</code>和<code>ProtobufEncoder</code>，并把provider-agent中的netty服务端<code>LengthFieldBasedFrameDecoder</code>及ProviderAgentDecoder替换为<code>ProtobufVarint32FrameDecoder</code>和<code>ProtobufDecoder</code>。<br>这就是我得出最高成绩的版本，qps5976.4，因为没有上6000逼死强迫症，又各种尝试最后还是没有能更近一步。</p><h3 id="赛后"><a href="#赛后" class="headerlink" title="赛后"></a>赛后</h3><p>答辩会上top10成绩的选手展示了他们的思路，其中有不少可以借鉴和学习的地方。另外也有一些相关的开源代码，接下来探讨一下可以改进的地方：</p><p>provider-agent和consumer-agent中EventLoop应该共享。当通过ServerChannel创建子channel后，子channel使用connect创建一个新的通道。如果共享了EventLoop则会使之在管道间共享，消除了额外的线程创建和所有相关的上下文切换的开销。<br>具体的做法也有点巧妙。这里以consumer-agent为例， 要使eventloop能够复用，在consumer-agent建立ServerBootstrap时使用了一个worker eventloopgroup，然后需要将其中的eventloop绑定到连接provider-agent的channel中。做法是，对于worker中的每一个eventloop都需要去建立一个bootstrap并作为其中的eventloopgroup，那么该bootstrap建立的所有连接都会被绑定到该eventloop。从而可以保证输入channel与输出channel是复用了一个eventloop的。此外，输入channel找到输出channel的方法是通过查找一个map&lt;eventloop, channel&gt;。</p><p>consumer-agent解码http请求时，有<code>HttpPostRequestDecoder</code>和<code>QueryStringDecoder</code>，后者更快。不过我的实现里是直接处理bytes数组，理论上效果更好。</p><p>使用 netty 自己封装的 EpollSocketChannel 来代替 NioSocketChannel。效果非常明显，题目环境下可以提升300qps。NioSocketChannel使用了jdk提供的nio，在linux下也会选择使用epoll，但是效果不好，可能是netty封装epoll带来的优化。才外使用边缘触发替代水平触发可以减少cpu的负载。</p><p>批量flush，批量decode。不再是writeAndFlush，而是多次write后flush一次。从而减少网络io的次数。decode同理。flush具体是通过重载ChannelOutboundHandler实现，重写其write方法。</p><p>其他细节：<br>    -Dio.netty.leakDetectionLevel=disabled 关闭ByteBuf 进行内存泄露的检测。<br>    EpollChannelOption.TCP_QUICKACK 开启TCP quick_ack<br>    ChannelOption.TCP_NODELAY<br>    减少对象的创建，encode和decode压缩到handler里去处理，hardcoding。</p><p>提升：<br>consumer的CPU是瓶颈，减少consumer-agent的开销<br>consumer-agent 透传？ 不解析consumer的http协议而是做纯粹的转发</p><p>线程数 CA3 PA1<br>RCVBUF_ALLOCATOR: FixedRecvByteBufAllocator</p><p>dalao的坑：透传希望能够做到零拷贝（splice） netty也有支持的方法spliceTo，但是linux不支持socket直接写到另一个socket，中间有pipe作为buffer（内核态）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;logo.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;上个学期抽空打了一下&lt;a href=&quot;https://tianchi.aliyun.com/programming/introduction.htm?spm=5176.100066.0.0.6acd33afBca
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>动态规划初探</title>
    <link href="http://lavaoxsea.com/2018/07/19/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E5%AE%9E%E6%88%98/"/>
    <id>http://lavaoxsea.com/2018/07/19/动态规划实战/</id>
    <published>2018-07-19T09:31:42.000Z</published>
    <updated>2019-02-25T16:41:00.785Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>动态规划（DP）问题是一道坎。相信很多人都有这种感觉，它是中高难度题的常客，蕴含了程序设计的经典思想。</p><p>这种技法或者说思想难以掌握是有原因的。它的核心目标是全局最优，而不是局部最优，这是反直觉的。人脑不是机器，所以我们往往陷入贪心的想法。我第一次遇到背包问题的时候，直接的想法是把物品按 价值/重量 排序，再依次取。这就好比小偷作案，总是先挑价值高又轻便的拿。但是这种经验并不是最优解。</p><p>说到背包问题，第一次看到正解后过了很长时间才真正理解。写本文之前，又读了一遍背包九讲(<a href="https://raw.githubusercontent.com/tianyicui/pack/master/V2.pdf" target="_blank" rel="noopener">pdf</a>)。确实背包问题是经典的DP问题，也是对我影响最深的DP问题。推荐对DP有一定理解之后再读。</p><p>写这篇博客之前，我对DP也是有些畏惧的，做题属于碰运气，有时能A，有时不行，还有些时候我都不清楚是要用DP解题。于是花了2周多的时间，刷了一些leetcode上的DP题目。</p><p><img src="leetcode.png" alt="leetcode"></p><p>目前算是初窥其貌，结合一些看到别人的总结，通俗得讲下我的理解。</p><h2 id="初步分析"><a href="#初步分析" class="headerlink" title="初步分析"></a>初步分析</h2><p>如果说DP的核心目标是寻找全局最优解，那这个最优解是如何确保的呢？通过划分子问题，DP问题常常是需要多步的决策，如背包要挑选物品。这些子问题往往是迭代的，一个自问题依赖于另一个的解。每个自问题都能到达最优解就获取到全局最优。因此可以说DP问题就是如何划分子问题并找到子问题的解。</p><p>从上面的描述里可以明显感觉到一个词，迭代。在我看来，迭代是符合人类思想的解决DP问题最直观的方式。</p><p>举个栗子：</p><p><img src="edit_distance.png" alt="edit distance"><br>来自leetcode72题，难度为hard。这道题我花了很久才做出来……而且回顾的时候又花了很久……</p><p>其实题目并不是特别难，但是看起来比较吓人。hard级的题目中DP都不是很直接，需要一定的转换。</p><p>根据题意，核心目标是匹配上两个字符串，通过delete、replace、add三种操作。那么子问题也就相对直接了，两个字符串的子串的匹配加上变成子串的步数即为结果。</p><p>这里我的想法是有三种策略：</p><ol><li>将str1的首字母替换为str2的首字母</li><li>删除str1的首字母，str2不变</li><li>找到str1中str2首字母出现的第一个位置，删除它及之前的所有字母，删除str2首字母。</li></ol><p>当str1和2中有一方为空时，删除另一方全部字母或添加一方全部字母即可，也就是步数加上剩余一方的长度。</p><p>代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> res = <span class="number">1</span> + getRes(i + <span class="number">1</span>, word1, str, map);</span><br><span class="line">res = Math.min(res, <span class="number">1</span> + getRes(i + <span class="number">1</span>, word1, str.substring(<span class="number">1</span>), map));</span><br><span class="line">res = Math.min(res, index + getRes(i + <span class="number">1</span>, word1, str.substring(index + <span class="number">1</span>), map));</span><br></pre></td></tr></table></figure></p><p>其中<code>getRes</code>为对子串递归调用。</p><p>但是这种解法直接提交以后出现TLE，超时错误。原因很简单，计算了重复状态。这里就可以引出DP中的常规操作，剪枝或者说记忆化搜索。我的代码中是使用了一个map来保存状态，通常更常用的方法是用一个数组记录。</p><p>完整代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">minDistance</span><span class="params">(String word1, String word2)</span> </span>&#123;</span><br><span class="line">    Map&lt;String, Integer[]&gt; map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    IntStream.range(<span class="number">0</span>, word2.length() + <span class="number">1</span>).forEach(x -&gt; map.put(word2.substring(x), <span class="keyword">new</span> Integer[word1.length() + <span class="number">1</span>]));</span><br><span class="line">    <span class="keyword">return</span> getRes(<span class="number">0</span>, word1, word2, map);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getRes</span><span class="params">(<span class="keyword">int</span> i, String word1, String str, Map&lt;String, Integer[]&gt; map)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (map.get(str)[i] != <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> map.get(str)[i];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(i &gt;= word1.length())</span><br><span class="line">        <span class="keyword">return</span> str.length();</span><br><span class="line">    <span class="keyword">int</span> res = <span class="number">1</span> + getRes(i + <span class="number">1</span>, word1, str, map);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(str.length() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        res = Math.min(res, <span class="number">1</span> + getRes(i + <span class="number">1</span>, word1, str.substring(<span class="number">1</span>), map));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> index = str.indexOf(word1.charAt(i));</span><br><span class="line">        <span class="keyword">if</span> (index != -<span class="number">1</span>) &#123;</span><br><span class="line">            res = Math.min(res, index + getRes(i + <span class="number">1</span>, word1, str.substring(index + <span class="number">1</span>), map));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    map.get(str)[i] = res;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="状态转移"><a href="#状态转移" class="headerlink" title="状态转移"></a>状态转移</h2><p>很多时候，动态规划问题的子问题并不好找。通过动态规划做题的经验我们知道有个叫递推方程的东西。而常见递推方程中递推的就是状态，也就是状态转移的过程，寻找状态的转移而去解决子问题是常见的思路。</p><p><img src="interleaving_string.png" alt="interleaving_string"></p><p>题目为leetcode97，由题意，需要用s1和s2组装成s3。s3从0到s3.length的长度都可以由s1和s2组成（子问题），s1和s2的组成方式则可以由i和j的二维数组表示。i代表s1的位置（substring(0, i)），j代表s2的位置。状态转移为<code>len = i + j - &gt; len + 1 = i + 1 + j / len + 1 = i + j + 1</code>满足相关位置的字符相同即可转移。代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isInterleave</span><span class="params">(String s1, String s2, String s3)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(s1.length() + s2.length() != s3.length())</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[s3.length() + <span class="number">1</span>][s3.length() + <span class="number">1</span>];</span><br><span class="line">    dp[<span class="number">0</span>][<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= s3.length(); i++) &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; i; j++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(s1.length() &gt;= i -j &amp;&amp; dp[j][i-j -<span class="number">1</span>] == <span class="number">1</span> &amp;&amp; s1.charAt(i - j - <span class="number">1</span>) == s3.charAt(i -<span class="number">1</span>)) &#123;</span><br><span class="line">                dp[j][i - j] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(s2.length() &gt;= i -j &amp;&amp; dp[i-j -<span class="number">1</span>][j] == <span class="number">1</span> &amp;&amp; s2.charAt(i - j - <span class="number">1</span>) == s3.charAt(i -<span class="number">1</span>)) &#123;</span><br><span class="line">                dp[i - j][j] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[s2.length()][s1.length()] == <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>很多DP的文章都在强调寻找递推式，但是递推式是靠近结果的一步。<strong>寻找递推式的过程，是划分子问题或者表示状态并得到状态的转移。</strong></p><h2 id="一些理论"><a href="#一些理论" class="headerlink" title="一些理论"></a>一些理论</h2><p>知乎上关于理解动态规划也有许多回答，多是关于理论和概念的。能够用动态规划解的题目，状态都具有这两种特性。</p><blockquote><p>最优子结构: 每个阶段的最优状态可以从之前某个阶段的某个或某些状态直接得到<br>无后效性: 而不管之前这个状态是如何得到的</p></blockquote><p>做到一些dp题的时候，我感觉DP和DFS（广度优先搜索）的过程十分相近。例如一个网格，需要从左上角通过向下向右走到右下角，节点带权值。再理解动态规划之前，这对我来说就是走过所有节点并取走过该节点时最小值的问题。这里有一个解释：</p><blockquote><p>每个阶段只有一个状态-&gt;递推<br>每个阶段的最优状态都是由上一个阶段的最优状态得到的-&gt;贪心<br>每个阶段的最优状态是由之前所有阶段的状态的组合得到的-&gt;搜索<br>每个阶段的最优状态可以从之前某个阶段的某个或某些状态直接得到而不管之前这个状态是如何得到的-&gt;动态规划。<br>                  ——<a href="https://www.zhihu.com/question/23995189/answer/35429905" target="_blank" rel="noopener">知乎</a></p></blockquote><p>这一段话是描述这几种常用算法和状态之间的关系的精髓。需要仔细想想，此处就不再赘述。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>实践出真知。在做了一定量的题目之后，会有自己的总结与归纳。动态规划的状态描述是个难点，一般都是用数组来保存状态。</p><ul><li>最常见的是数组的维度代表状态位置，比如一个二维数组中的某个值。</li><li>数组的维度可以表示状态的维度，所有维度组合为当前状态。</li><li>用pal[start][end]来存储状态，start和end分别代表位置。</li><li>用数组的第一维表示迭代的层数，第二维表示位置.</li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>刷了动态规划的题，直观的感受是，我如果知道要用DP解题，80%以上的Medium都可以解出来，但是hard估计也就50%不到。首先如何识别一道题是需要DP解题的问题？这估计只有在以后的实战中判断了。hard级别的动态规划难点也主要在它的不直观或者说需要多绕一个弯，可能根据题意本身解题会一头雾水，但是换个角度就豁然开朗，这需要的就不只是DP的掌握了。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;p&gt;动态规划（DP）问题是一道坎。相信很多人都有这种感觉，它是中高难度题的常客，蕴含了程序设计的经典思想。&lt;/p&gt;
&lt;p
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>使用hexo搭建Blog</title>
    <link href="http://lavaoxsea.com/2018/07/15/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BABlog/"/>
    <id>http://lavaoxsea.com/2018/07/15/使用hexo搭建Blog/</id>
    <published>2018-07-15T11:39:22.000Z</published>
    <updated>2019-02-26T02:50:53.458Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><blockquote><p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 –<a href="https://hexo.io/zh-cn/docs/index.html" target="_blank" rel="noopener">hexo</a>文档</p></blockquote><p><img src="hexo_intro.png" alt="hexo"></p><p><a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">hexo</a>基于node.js和npm。它生成静态页面，对使用者而言高度封装，几乎不需要前端知识，各种已有主题又十分美观，而且切换也十分方便，可以说是个人博客的完美选择。</p><h2 id="安装（MacOS）"><a href="#安装（MacOS）" class="headerlink" title="安装（MacOS）"></a>安装（MacOS）</h2><p>安装git <code>brew install git</code><br>安装npm <code>wget -qO- https://raw.github.com/creationix/nvm/master/install.sh | sh</code><br>重启终端 <code>nvm install stable</code><br>安装hexo <code>npm install -g hexo-cli</code></p><p>##基础配置<br>_config.yml包含了博客的大部分配置，配置内容可在文档中查看。</p><p><img src="dir.png" alt="展示"></p><ul><li>source 存放文章<ul><li>_drafts 存放草稿，默认不显示</li><li>_posts 存放文章</li></ul></li><li>themes 存放主题</li><li>scaffolds 模版，新建文章时受模版控制</li><li>public 存放生成的html等文件</li></ul><h2 id="基础使用"><a href="#基础使用" class="headerlink" title="基础使用"></a>基础使用</h2><p><code>hexo init &lt;folder&gt;</code> 在文件夹中初始化hexo<br><code>hexo new [layout] &lt;title&gt;</code> 新建文章，layout指draft或post，draft为草稿，post为发布的文章<br><code>hexo generator</code> 将markdown转为静态页面<br><code>hexo publish [layout] &lt;filename&gt;</code> 发表草稿，将draft中指定的文件转到post中<br><code>hexo server</code> 启动hexo服务器，默认端口4000，可以通过-p设置<br><code>hexo clean</code> 清除缓存文件和已经生成的静态文件<br><code>hexo list</code> 展示网站信息</p><h2 id="标签插件"><a href="#标签插件" class="headerlink" title="标签插件"></a>标签插件</h2><p>包含大量非Markdown语法，不便迁移，尽量不使用。两个例子：</p><p>引用块:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;% blockquote [author[, source]] [link] [source_link_title] %&#125;</span><br><span class="line">content</span><br><span class="line">&#123;% endblockquote %&#125;</span><br></pre></td></tr></table></figure></p><p>代码块:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;% codeblock [title] [lang:language] [url] [link text] %&#125;</span><br><span class="line">code snippet</span><br><span class="line">&#123;% endcodeblock %&#125;</span><br></pre></td></tr></table></figure></p><h2 id="主题"><a href="#主题" class="headerlink" title="主题"></a>主题</h2><p><a href="https://hexo.io/themes/" target="_blank" rel="noopener">官方主题页</a>包含了主题展示和github跳转，按照github项目中README安装即可。</p><p>本人使用的是<a href="https://github.com/kywk/hexo-theme-casper" target="_blank" rel="noopener">casper的修改版</a>。<br>所有和主题相关的文件夹都在themes中并且是可以自定义和修改的，主题目录下提供了_config.yml文件。比如图标、logo、favicon等。此外，可以进一步通过修改js和css为你想要的样式。</p><h2 id="资源文件夹"><a href="#资源文件夹" class="headerlink" title="资源文件夹"></a>资源文件夹</h2><p>如果你的Hexo项目中只有少量图片，那最简单的方法就是将它们放在 source/images 文件夹中。然后通过类似于 <img src="/images/image.jpg" alt="">的方法访问它们。</p><p>对于那些想要更有规律地提供图片和其他资源以及想要将他们的资源分布在各个文章上的人来说，可以通过将 config.yml 文件中的 post_asset_folder 选项设为 true 来打开。</p><h2 id="about页面"><a href="#about页面" class="headerlink" title="about页面"></a>about页面</h2><p><code>hexo new page about</code> 创建页面。<br>修改Front-matter部分，layout为false，comments为false</p><h2 id="评论"><a href="#评论" class="headerlink" title="评论"></a>评论</h2><p>本人使用了valine，主要工作是取theme文件夹里修改相关的代码。有些主题提供了一些评论系统，直接配置即可。</p><p><a href="https://valine.js.org/quickstart.html" target="_blank" rel="noopener">官方教程</a>过程很简明。先去LeanCloud上注册账号，获取AppKey及AppId，填到评论的js代码中。</p><p>最好再配置一下LeanCloud的安全域名，可以保证只有Blog的访问。</p><h2 id="分享"><a href="#分享" class="headerlink" title="分享"></a>分享</h2><p>其实就是一些a标签，该主题自带，不过是Twitter、脸书及Google的，我自己照着加了一个微博的。代码如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">""</span> <span class="attr">href</span>=<span class="string">"http://service.weibo.com/share/share.php?url=&lt;%- permalink %&gt;"</span> <span class="attr">onclick</span>=<span class="string">"window.open(this.href, 'weibo-share', 'width=550,height=235');return false;"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">""</span>&gt;</span>Weibo<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure><p>似乎baidushare也很常用，但是……有点丑。</p><h2 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h2><p>铛铛铛～ 终于到激动人心的时候了，上 vps/github.io!</p><h4 id="github-io"><a href="#github-io" class="headerlink" title="github.io"></a>github.io</h4><p>需要新建一个&lt;github-name&gt;.github.io 的仓库</p><p>使用git部署，需要先安装插件： <code>npm install hexo-deployer-git --save</code><br>修改config.yml中的deploy部分为</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line"><span class="attr"> - type:</span> <span class="string">git</span></span><br><span class="line"><span class="attr">   repo:</span> <span class="string">&lt;repo-name&gt;</span></span><br><span class="line"><span class="attr">   branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure><p>之后执行<code>hexo deploy</code>部署到github上，即可通过仓库名访问。可以自行配置域名，在此不赘述。</p><h4 id="vps"><a href="#vps" class="headerlink" title="vps"></a>vps</h4><p>vps需要从 Vultr 或者 DigitalOcean 等供应商处租赁，常用的配置价格为5刀/月<br>部署其实也很简单…… 先安装一个Nginx，记得防火墙开启权限 步骤大致如下（Ubuntu）：<br>安装nginx <code>apt-get install nginx</code><br>防火墙允许 <code>ufw allow &quot;Nginx Full&quot;</code></p><p>然后配置一下nginx，使之能够显示博客站点<br>创建站点配置文件<code>vi /etc/nginx/conf.d/blog.conf</code>，内容为：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        listen [::]:80;</span><br><span class="line">        root /var/www/blog/html;</span><br><span class="line">        index index.html index.htm index.nginx-debian.html;</span><br><span class="line">        server_name example.com www.example.com;</span><br><span class="line">        access_log /var/log/nginx/blog_access.log;</span><br><span class="line">        error_log /var/log/nginx/blog_error.log;</span><br><span class="line">        error_page 404 /404.html;</span><br><span class="line">        location ~* ^.+\.(ico|gif|jpg|jpeg|png)$ &#123;</span><br><span class="line">          root /var/www/blog/html;</span><br><span class="line">          access_log   off;</span><br><span class="line">          expires      1d;</span><br><span class="line">        &#125;</span><br><span class="line">        location ~* ^.+\.(css|js|txt|xml|swf|wav)$ &#123;</span><br><span class="line">          root /var/www/blog/html;</span><br><span class="line">          access_log   off;</span><br><span class="line">          expires      10m;</span><br><span class="line">        &#125;</span><br><span class="line">        location / &#123;</span><br><span class="line">                try_files $uri $uri/ =404;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>修改/etc/nginx/sites-available<code>listen 80 default_server;</code>为<code>listen 80;</code><br>并在nginx中的http块中添加<code>include /etc/nginx/conf.d/*.conf;</code>和<code>include /etc/nginx/sites-enabled/*;</code>重启nginx并添加开机启动项。</p><p>之后配置git钩子 也就是一个空的git仓库，当本地的hexo推送给这个仓库时，会有个脚本执行自动拉取代码。<br><code>mkdir -p /var/www/blog/html</code>路径用于存放站点<br><code>git init --bare blog.git</code>创建空仓库<br><code>cd blog.git/hooks</code>准备创建钩子脚本<br><code>vi post-receive</code>创建脚本，内容如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">git --work-tree=/var/www/blog/html --git-dir=/var/www/blog/html/blog.git checkout -f</span><br></pre></td></tr></table></figure><p>git checkout -f 会强制拉取代码</p><p>本地配置config.yml的deploy部分：<br><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line"><span class="attr">   type:</span> <span class="string">git</span></span><br><span class="line"><span class="attr">   repo:</span> </span><br><span class="line"><span class="attr">   vps:</span> <span class="attr">ssh://&lt;username&gt;@&lt;ip&gt;:&lt;port&gt;/var/www/path/to/blog.git</span></span><br><span class="line"><span class="attr">   branch:</span> <span class="string">master</span></span><br></pre></td></tr></table></figure></p><p>这种方式可以配置ssh的端口，其中的username需要可以免密登陆vps。</p><h2 id="404"><a href="#404" class="headerlink" title="404"></a>404</h2><p>首先需要创建一个自定义404页面，与about页相似 <code>hexo new page 404</code><br>修改Front-matter部分，layout为false，permalink为/404.html，comments为false</p><p>与/about不同，它会在根目录生成404.html而不是/404/index.html。填入内容即可</p><p>对于github pages：检测到根目录的404.html时，会将其作为404页面</p><p>对于nginx：修改站点conf，如blog.conf，添加error page条目error_page 404 /404.html;</p><h2 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h2><p>如今，https也是博客标配了，这里我使用最方便的Let’s Encrypt方案，用其提供的certbot来自动签发证书。之后配合nginx配置https。<br>配置之前要确保80和443端口是打开的。debian使用的iptables，通过下两行命令实现：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iptables -A INPUT -p tcp --dport 80 -j ACCEPT</span><br><span class="line">iptables -A INPUT -p tcp --dport 443 -j ACCEPT</span><br></pre></td></tr></table></figure></p><p>debian安装certbot，并按照提示配置:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install certbot python-certbot-nginx</span><br><span class="line">sudo certbot --nginx</span><br></pre></td></tr></table></figure></p><p>生成的证书在/etc/letsencrypt/live/$domain目录下。由于证书会在30天后过期，因此，需要使用cron脚本自动更新。如下：<br><code>0 3 15 * * root certbot renew &gt; /dev/null</code><br>每15天凌晨3点更新证书。</p><p>certbot在配置完成后，会自动修改你的&lt;server&gt;.conf文件，修改监听443端口并指定证书和私钥的位置。使用<code>nginx -s reload</code>使配置生效，此时访问就已经是https的方式了。</p><h2 id="Outro"><a href="#Outro" class="headerlink" title="Outro"></a>Outro</h2><p>一整天时间搭建Blog，基本达到心里预期，基本都很简明</p><p>后续还有SEO、Google Analysis及全站Https</p><p>在反复沮丧中坚持✊</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Intro&quot;&gt;&lt;a href=&quot;#Intro&quot; class=&quot;headerlink&quot; title=&quot;Intro&quot;&gt;&lt;/a&gt;Intro&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引
      
    
    </summary>
    
    
      <category term="hexo, Blog" scheme="http://lavaoxsea.com/tags/hexo-Blog/"/>
    
  </entry>
  
</feed>
